{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOWO (Leave-One-World-Out) Training - Google Colab\n",
    "\n",
    "This notebook trains all 6 LOWO models for Sprint 5 generalization experiments.\n",
    "\n",
    "**Requirements:**\n",
    "- Enable GPU: Runtime > Change runtime type > T4 GPU (or A100 for faster training)\n",
    "- Mount Google Drive for checkpoint persistence\n",
    "\n",
    "**Estimated Time:**\n",
    "- T4 GPU: ~45-60 min per model (~5-6 hours total)\n",
    "- A100 GPU: ~15-20 min per model (~2 hours total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory in Drive\n",
    "!mkdir -p /content/drive/MyDrive/macro_emulator/runs\n",
    "!mkdir -p /content/drive/MyDrive/macro_emulator/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (UPDATE THIS URL to your repo)\n",
    "%cd /content\n",
    "\n",
    "# Option 1: Clone from GitHub (if public or with token)\n",
    "# !git clone https://github.com/YOUR_USERNAME/macro_simulator.git\n",
    "\n",
    "# Option 2: Upload from local machine\n",
    "# Use the file browser on the left to upload a zip of your repo\n",
    "# Then uncomment:\n",
    "# !unzip macro_simulator.zip\n",
    "\n",
    "# Option 3: Clone from Drive (if you've synced your repo there)\n",
    "# !cp -r /content/drive/MyDrive/macro_simulator /content/macro_simulator\n",
    "\n",
    "print(\"Choose one of the options above and uncomment it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%cd /content/macro_simulator\n",
    "!pip install -e \".[dev]\" -q\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check - run fast tests\n",
    "!python -m pytest -m \"fast\" -v --tb=line -q 2>&1 | tail -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate or Load Dataset\n",
    "\n",
    "You have two options:\n",
    "1. Generate fresh dataset (takes ~30-60 min)\n",
    "2. Load pre-generated dataset from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATASET_PATH = \"datasets/v1.0\"\n",
    "DRIVE_DATASET_PATH = \"/content/drive/MyDrive/macro_emulator/datasets/v1.0\"\n",
    "\n",
    "# Check if dataset exists in Drive\n",
    "if os.path.exists(DRIVE_DATASET_PATH) and os.path.exists(os.path.join(DRIVE_DATASET_PATH, \"manifest.json\")):\n",
    "    print(\"Found existing dataset in Google Drive!\")\n",
    "    print(\"Symlinking to local path...\")\n",
    "    !ln -sf {DRIVE_DATASET_PATH} {DATASET_PATH}\n",
    "    print(\"Dataset ready.\")\n",
    "else:\n",
    "    print(\"No dataset found in Drive. Will generate new dataset.\")\n",
    "    print(\"This will take ~30-60 minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset if not found (skip if already exists)\n",
    "import os\n",
    "\n",
    "if not os.path.exists(os.path.join(DATASET_PATH, \"manifest.json\")):\n",
    "    print(\"Generating dataset with 10k samples per world...\")\n",
    "    print(\"This will take ~30-60 minutes. Go grab a coffee!\")\n",
    "    \n",
    "    !python -m data.scripts.generate_dataset \\\n",
    "        --world all \\\n",
    "        --n_samples 10000 \\\n",
    "        --seed 42 \\\n",
    "        --output {DATASET_PATH}\n",
    "    \n",
    "    # Copy to Drive for persistence\n",
    "    print(\"\\nCopying dataset to Google Drive for future use...\")\n",
    "    !cp -r {DATASET_PATH} {DRIVE_DATASET_PATH}\n",
    "    print(\"Dataset saved to Drive!\")\n",
    "else:\n",
    "    print(\"Dataset already exists. Skipping generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate dataset\n",
    "!python -m data.scripts.validate_dataset --path {DATASET_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LOWO Training\n",
    "\n",
    "Train 6 models, each with one simulator family held out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LOWO experiments\n",
    "LOWO_WORLDS = ['lss', 'var', 'nk', 'rbc', 'switching', 'zlb']\n",
    "\n",
    "# Symlink runs directory to Drive for persistence\n",
    "DRIVE_RUNS_PATH = \"/content/drive/MyDrive/macro_emulator/runs\"\n",
    "!rm -rf runs  # Remove local runs if exists\n",
    "!ln -sf {DRIVE_RUNS_PATH} runs\n",
    "\n",
    "print(f\"Runs will be saved to: {DRIVE_RUNS_PATH}\")\n",
    "print(f\"\\nWill train {len(LOWO_WORLDS)} LOWO models:\")\n",
    "for world in LOWO_WORLDS:\n",
    "    print(f\"  - lowo_exclude_{world}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which models are already trained\n",
    "import os\n",
    "\n",
    "remaining_worlds = []\n",
    "for world in LOWO_WORLDS:\n",
    "    checkpoint_path = f\"runs/lowo_exclude_{world}/best_checkpoint.pt\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"[DONE] lowo_exclude_{world}\")\n",
    "    else:\n",
    "        print(f\"[TODO] lowo_exclude_{world}\")\n",
    "        remaining_worlds.append(world)\n",
    "\n",
    "print(f\"\\n{len(remaining_worlds)} models remaining to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all remaining LOWO models\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "for i, world in enumerate(remaining_worlds):\n",
    "    config_path = f\"configs/lowo_exclude_{world}.yaml\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training LOWO model {i+1}/{len(remaining_worlds)}: exclude_{world}\")\n",
    "    print(f\"Config: {config_path}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run training\n",
    "    !python -m emulator.training.trainer --config {config_path}\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nCompleted exclude_{world} in {elapsed/60:.1f} minutes\")\n",
    "    print(f\"Checkpoint saved to: runs/lowo_exclude_{world}/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL LOWO MODELS TRAINED!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate LOWO Transfer\n",
    "\n",
    "Evaluate each model on its held-out world to measure generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate all LOWO models\n# For each model, evaluate on BOTH the held-out world (transfer) and in-domain worlds\nimport json\nimport os\n\nresults = {}\n\nfor world in LOWO_WORLDS:\n    checkpoint_path = f\"runs/lowo_exclude_{world}/best_checkpoint.pt\"\n    \n    if not os.path.exists(checkpoint_path):\n        print(f\"[SKIP] No checkpoint for lowo_exclude_{world}\")\n        continue\n    \n    print(f\"\\n{'='*50}\")\n    print(f\"Evaluating lowo_exclude_{world}\")\n    print(f\"{'='*50}\")\n    \n    # Evaluate on held-out world (transfer performance)\n    held_out_output = f\"runs/lowo_exclude_{world}/eval_held_out.json\"\n    print(f\"\\n1. Evaluating on HELD-OUT world ({world})...\")\n    !python -m emulator.eval.evaluate \\\n        --checkpoint {checkpoint_path} \\\n        --dataset {DATASET_PATH} \\\n        --worlds {world} \\\n        --output {held_out_output}\n    \n    # Evaluate on in-domain worlds (trained worlds)\n    in_domain_worlds = [w for w in LOWO_WORLDS if w != world]\n    in_domain_str = \",\".join(in_domain_worlds)\n    in_domain_output = f\"runs/lowo_exclude_{world}/eval_in_domain.json\"\n    print(f\"\\n2. Evaluating on IN-DOMAIN worlds ({in_domain_str})...\")\n    !python -m emulator.eval.evaluate \\\n        --checkpoint {checkpoint_path} \\\n        --dataset {DATASET_PATH} \\\n        --worlds {in_domain_str} \\\n        --output {in_domain_output}\n    \n    # Load and combine results\n    results[world] = {}\n    if os.path.exists(held_out_output):\n        with open(held_out_output) as f:\n            results[world]['held_out'] = json.load(f)\n    if os.path.exists(in_domain_output):\n        with open(in_domain_output) as f:\n            results[world]['in_domain'] = json.load(f)\n    \n    print(f\"Results saved for lowo_exclude_{world}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate LOWO comparison table\nimport pandas as pd\n\nif results:\n    rows = []\n    for world, res in results.items():\n        held_out_nrmse = \"N/A\"\n        in_domain_nrmse = \"N/A\"\n        transfer_gap = \"N/A\"\n        \n        # Extract NRMSE from results\n        if 'held_out' in res and 'overall' in res['held_out']:\n            held_out_nrmse = res['held_out']['overall'].get('nrmse', 'N/A')\n        if 'in_domain' in res and 'overall' in res['in_domain']:\n            in_domain_nrmse = res['in_domain']['overall'].get('nrmse', 'N/A')\n        \n        # Compute transfer gap (ratio of held-out to in-domain error)\n        if isinstance(held_out_nrmse, (int, float)) and isinstance(in_domain_nrmse, (int, float)):\n            if in_domain_nrmse > 0:\n                transfer_gap = f\"{held_out_nrmse / in_domain_nrmse:.2f}x\"\n        \n        rows.append({\n            'Held-Out World': world.upper(),\n            'NRMSE (held-out)': f\"{held_out_nrmse:.4f}\" if isinstance(held_out_nrmse, float) else held_out_nrmse,\n            'NRMSE (in-domain)': f\"{in_domain_nrmse:.4f}\" if isinstance(in_domain_nrmse, float) else in_domain_nrmse,\n            'Transfer Gap': transfer_gap,\n        })\n    \n    df = pd.DataFrame(rows)\n    print(\"\\n\" + \"=\"*60)\n    print(\"LOWO Transfer Results Summary\")\n    print(\"=\"*60)\n    print(\"\\nTransfer Gap = (held-out NRMSE) / (in-domain NRMSE)\")\n    print(\"  - Gap ~ 1.0: Good generalization\")\n    print(\"  - Gap > 1.5: Poor generalization (model overfits to training worlds)\")\n    print()\n    print(df.to_string(index=False))\n    \n    # Save to CSV\n    csv_path = 'runs/lowo_transfer_results.csv'\n    df.to_csv(csv_path, index=False)\n    print(f\"\\nResults saved to {csv_path}\")\n    \n    # Also save full results as JSON\n    json_path = 'runs/lowo_all_results.json'\n    with open(json_path, 'w') as f:\n        json.dump(results, f, indent=2, default=str)\n    print(f\"Full results saved to {json_path}\")\nelse:\n    print(\"No results to display yet. Run the evaluation cell first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Results\n",
    "\n",
    "All checkpoints and results are automatically saved to Google Drive.\n",
    "\n",
    "Location: `/content/drive/MyDrive/macro_emulator/runs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved checkpoints\n",
    "!ls -la {DRIVE_RUNS_PATH}/lowo_*/\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All results saved to Google Drive!\")\n",
    "print(f\"Path: {DRIVE_RUNS_PATH}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Create a zip of all LOWO results for download\n",
    "!cd {DRIVE_RUNS_PATH} && zip -r lowo_results.zip lowo_exclude_*\n",
    "\n",
    "print(f\"\\nZip file created: {DRIVE_RUNS_PATH}/lowo_results.zip\")\n",
    "print(\"You can download this file from Google Drive.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}